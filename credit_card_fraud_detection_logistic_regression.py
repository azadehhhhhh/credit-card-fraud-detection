# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection - Logistic Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/azadehhhhhh/credit-card-fraud-detection/blob/main/Credit%20Card%20Fraud%20Detection%20Using%20Machine%20Learning/Code/Credit%20Card%20Fraud%20Detection%20-%20Logistic%20Regression.ipynb

# Credit Card Fraud Detection - Logistic Regression

Importing the Dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score , roc_auc_score

# loading the dataset to a Pandas DataFrame
credit_card_data = pd.read_csv('/content/creditcard.csv')

# first 5 rows of the dataset
credit_card_data.head()

credit_card_data.tail()

# dataset informations
credit_card_data.info()

# checking the number of missing values in each column
credit_card_data.isnull().sum()

# distribution of legit transactions & fraudulent transactions
credit_card_data['Class'].value_counts()

"""This Dataset is highly unblanced

0 --> Normal Transaction

1 --> fraudulent transaction
"""

# separating the data for analysis
legit = credit_card_data[credit_card_data.Class == 0]
fraud = credit_card_data[credit_card_data.Class == 1]

print(legit.shape)
print(fraud.shape)

# statistical measures of the data
legit.Amount.describe()

fraud.Amount.describe()

# compare the values for both transactions
credit_card_data.groupby('Class').mean()

X = credit_card_data.drop(columns=['Class'], axis=1)
y = credit_card_data['Class']

print("X shape:", X.shape)
print("y shape:", y.shape)
y.value_counts()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print("Train shape:", X_train.shape, y_train.shape)
print("Test shape:", X_test.shape, y_test.shape)

model = LogisticRegression(
    max_iter=1000,
    class_weight='balanced',
    n_jobs=-1
)

model.fit(X_train, y_train)

custom_threshold = 0.30
y_pred_custom = (y_proba >= custom_threshold).astype(int)

print("\n=== Classification Report (threshold = 0.30) ===")
print(classification_report(y_test, y_pred_custom))

from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Compute ROC values
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
roc_auc = roc_auc_score(y_test, y_proba)

plt.figure(figsize=(7,5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
plt.plot([0,1], [0,1], '--', color='grey')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd
from sklearn.metrics import precision_score, recall_score, f1_score

thresholds = [0.50, 0.40, 0.30, 0.20, 0.10]
results = []

for th in thresholds:
    y_pred_th = (y_proba >= th).astype(int)
    precision = precision_score(y_test, y_pred_th, zero_division=0)
    recall = recall_score(y_test, y_pred_th)
    f1 = f1_score(y_test, y_pred_th)

    results.append([th, precision, recall, f1])

df_results = pd.DataFrame(results, columns=["Threshold", "Precision", "Recall", "F1"])
df_results

